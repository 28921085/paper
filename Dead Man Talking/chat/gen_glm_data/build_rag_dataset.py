from langchain_ollama import OllamaEmbeddings
from rag_database import DatabaseManager
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader

userTag="User"
AITag = "Jimç¨‹å»ºè©•"
def parse_conversation(file_path):
    conversations = []
    with open(file_path, 'r', encoding='utf-8') as file:
        content = file.read()  # è®€å–æ•´å€‹æª”æ¡ˆ
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)
        conversation_parts = text_splitter.split_text(content)  # ğŸ”¹ é©ç”¨æ–¼ç´”æ–‡å­—

        # å°‡æ¯ä¸€æ®µè½‰ç‚º Document ç‰©ä»¶
        for part in conversation_parts:
            conversations.append(Document(page_content=part.strip()))

    return conversations
# def parse_conversation(file_path):
#     conversations = []
#     with open(file_path, 'r', encoding='utf-8') as file:
#         lines = file.readlines()

#     current_user = None
#     current_assistant = None

#     for line in lines:
#         if line.startswith("user: "):
#             current_user = line.strip().replace("user: ", "")
#         elif line.startswith("assistant: ") and current_user:
#             current_assistant = line.strip().replace("assistant: ", "")
#             conversations.append(f"{userTag}: {current_user} | {AITag}: {current_assistant}")
#             current_user = None

#     return conversations
# # ğŸ”¹ è®€å–ä¸¦è§£ææª”æ¡ˆ
# def parse_conversation(file_path):
#     conversations = []
#     with open(file_path, 'r', encoding='utf-8') as file:
#         lines = file.readlines()

#     current_conversation = []

#     for line in lines:
#         if line.strip() == "":  # ç©ºç™½è¡Œæ¨™ç¤ºä¸€æ®µå°è©±çš„çµæŸ
#             if current_conversation:
#                 conversations.append("\n".join(current_conversation))
#                 current_conversation = []
#         elif line.startswith("user: "):
#             current_conversation.append(f"{userTag}: {line.strip().replace('user: ', '')}")
#         elif line.startswith("assistant: "):
#             current_conversation.append(f"{AITag}: {line.strip().replace('assistant: ', '')}")
#         else:
#             current_conversation.append(line.strip())

#     if current_conversation:  # æª”æ¡ˆæœ«å°¾çš„å°è©±
#         conversations.append("\n".join(current_conversation))

#     return conversations

embeddings = OllamaEmbeddings(model="llama3")
# DB_PATH = "Jim"
DB_PATH = "Law"

# è®€å–ä¸¦è§£ææª”æ¡ˆ
# file_paths = [f"conversation/jim-{i}_output.txt" for i in range(1, 8)]
# file_paths = [f"conversation/jim-{i}.txt" for i in range(1, 8)]
file_paths = ["law.txt"]
parsed_conversations = []
# for file in file_paths:
#     conversation = parse_conversation(file)
#     for data in conversation:
#         parsed_conversations.append(Document(page_content=data))  # âœ… ä¿®æ­£é»ï¼šè½‰æ›ç‚º Document


for file in file_paths:
    conversations = parse_conversation(file)
    parsed_conversations.extend(conversations)  # âœ… å°‡åˆ†å‰²å¾Œçš„å°è©±åŠ å…¥é™£åˆ—

# åˆå§‹åŒ–è³‡æ–™åº«
db_manager = DatabaseManager(DB_PATH, embeddings, parsed_conversations)

# æ¸¬è©¦æŸ¥è©¢
db_manager.search_data("æœªæˆå¹´äºº", 20)