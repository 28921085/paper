from langchain_ollama import OllamaEmbeddings
from rag_database import DatabaseManager
from langchain.schema import Document

userTag="User"
AITag = "Jimç¨‹å»ºè©•"
def parse_conversation(file_path):
    conversations = []
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()

    current_user = None
    current_assistant = None

    for line in lines:
        if line.startswith("user: "):
            current_user = line.strip().replace("user: ", "")
        elif line.startswith("assistant: ") and current_user:
            current_assistant = line.strip().replace("assistant: ", "")
            conversations.append(f"{userTag}: {current_user} | {AITag}: {current_assistant}")
            current_user = None

    return conversations
# # ğŸ”¹ è®€å–ä¸¦è§£ææª”æ¡ˆ
# def parse_conversation(file_path):
#     conversations = []
#     with open(file_path, 'r', encoding='utf-8') as file:
#         lines = file.readlines()

#     current_conversation = []

#     for line in lines:
#         if line.strip() == "":  # ç©ºç™½è¡Œæ¨™ç¤ºä¸€æ®µå°è©±çš„çµæŸ
#             if current_conversation:
#                 conversations.append("\n".join(current_conversation))
#                 current_conversation = []
#         elif line.startswith("user: "):
#             current_conversation.append(f"{userTag}: {line.strip().replace('user: ', '')}")
#         elif line.startswith("assistant: "):
#             current_conversation.append(f"{AITag}: {line.strip().replace('assistant: ', '')}")
#         else:
#             current_conversation.append(line.strip())

#     if current_conversation:  # æª”æ¡ˆæœ«å°¾çš„å°è©±
#         conversations.append("\n".join(current_conversation))

#     return conversations

embeddings = OllamaEmbeddings(model="llama3")
DB_PATH = "Jim"

# è®€å–ä¸¦è§£ææª”æ¡ˆ
# file_paths = [f"conversation/jim-{i}_output.txt" for i in range(1, 8)]
file_paths = [f"conversation/jim-{i}.txt" for i in range(1, 8)]
parsed_conversations = []
for file in file_paths:
    conversation = parse_conversation(file)
    for data in conversation:
        parsed_conversations.append(Document(page_content=data))  # âœ… ä¿®æ­£é»ï¼šè½‰æ›ç‚º Document

# åˆå§‹åŒ–è³‡æ–™åº«
db_manager = DatabaseManager(DB_PATH, embeddings, parsed_conversations)

# æ¸¬è©¦æŸ¥è©¢
db_manager.search_data("Jimå°æ“‡å¶æœ‰ä»€éº¼æ¢ä»¶",20)