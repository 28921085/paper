from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from rag_database import DatabaseManager

embeddings = OllamaEmbeddings(model="llama3")
DB_PATH = "Jim"

# # åˆå§‹è³‡æ–™
# initial_documents = [
#     Document(page_content="å°ç£æ˜¯äºæ´²ä¸€å€‹ç¾éº—çš„å³¶å¶¼ï¼Œä»¥ç¾é£Ÿå’Œå‹å–„çš„äººæ°‘èåã€‚"),
#     Document(page_content="æ—¥æœ¬ä»¥å…¶å‚³çµ±æ–‡åŒ–å’Œç¾ä»£ç§‘æŠ€ä¸¦å­˜çš„ç¨ç‰¹é¢¨è²Œèåæ–¼ä¸–ã€‚"),
#     Document(page_content="ç¾åœ‹æ“æœ‰å¤šæ¨£åŒ–çš„æ–‡åŒ–å’Œé¢¨æ™¯ï¼Œä¸¦ä»¥ç§‘æŠ€ç™¼å±•å’Œå‰µæ–°è‘—ç¨±ã€‚"),
#     Document(page_content="æ³•åœ‹ä»¥å…¶ç¾é£Ÿã€æ™‚å°šå’Œè—è¡“èåï¼Œæ˜¯æ­æ´²æ—…éŠç†±é–€ç›®çš„åœ°ã€‚"),
# ]

# åˆå§‹åŒ–è³‡æ–™åº«
# db_manager = DatabaseManager(DB_PATH, embeddings, initial_documents)
db_manager = DatabaseManager(DB_PATH, embeddings)


# æ¸¬è©¦æŸ¥è©¢
db_manager.search_data("Jimå°æ“‡å¶æœ‰ä»€éº¼æ¢ä»¶",10)


# # æ¸¬è©¦æ›´æ–°
# update_data(db, "å°ç£æ˜¯äºæ´²ä¸€å€‹ç¾éº—çš„å³¶å¶¼ï¼Œä»¥ç¾é£Ÿå’Œå‹å–„çš„äººæ°‘èåã€‚", "å°ç£æ“æœ‰è±å¯Œçš„å¤œå¸‚æ–‡åŒ–ï¼Œå¸å¼•è¨±å¤šè§€å…‰å®¢ã€‚", DB_PATH)  
# search_data(db, "å°ç£")  

# # æ¸¬è©¦åˆªé™¤
# db = delete_data(db, "æ—¥æœ¬ä»¥å…¶å‚³çµ±æ–‡åŒ–å’Œç¾ä»£ç§‘æŠ€ä¸¦å­˜çš„ç¨ç‰¹é¢¨è²Œèåæ–¼ä¸–ã€‚", DB_PATH)  
# search_data(db, "æ—¥æœ¬")  


# # ä½¿ç”¨ similarity_search_with_score() ä¾†å–å¾—ç›¸ä¼¼åº¦åˆ†æ•¸
# results = db.similarity_search_with_score(query, k=2)

# # é¡¯ç¤ºçµæœ (æŒ‰ç›¸ä¼¼åº¦æ’åº)
# print("ğŸ” æŸ¥è©¢çµæœ (åŒ…å«ç›¸ä¼¼åº¦åˆ†æ•¸)ï¼š")
# for i, (doc, score) in enumerate(sorted(results, key=lambda x: x[1], reverse=True), 1):
#     print(f"{i}. {doc.page_content} (ç›¸ä¼¼åº¦: {score:.4f})")